{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import csv\n",
    "import numpy as np  # http://www.numpy.org\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from math import log, floor, ceil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "X = list()\n",
    "y = list()\n",
    "XX = list()\n",
    "with open(\"pima-indians-diabetes.csv\") as f:\n",
    "        next(f, None)\n",
    "        for line in csv.reader(f, delimiter=\",\"):\n",
    "            xline = []\n",
    "            for i in range(len(line)):\n",
    "                if i in set([i for i in range(0, 9)]):\n",
    "                    xline.append(ast.literal_eval(line[i]))\n",
    "                else:\n",
    "                    xline.append(line[i])\n",
    "\n",
    "            X.append(xline[:-1])\n",
    "            y.append(xline[-1])\n",
    "            XX.append(xline[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_y):\n",
    "\n",
    "    entropy = 0\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    class_y = np.array(class_y)\n",
    "    (unique, counts) = np.unique(class_y, return_counts=True)\n",
    "    p = np.array(counts)/len(class_y)\n",
    "    entropy = round(np.sum(-1*p.T*np.log2(p)), 3)\n",
    "    #############################################\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_classes(X, y, split_attribute, split_val):\n",
    "    # Inputs:\n",
    "    #   X               : data containing all attributes\n",
    "    #   y               : labels\n",
    "    #   split_attribute : column index of the attribute to split on\n",
    "    #   split_val       : a numerical value to divide the split_attribute\n",
    "\n",
    "    # TODO: Partition the data(X) and labels(y) based on the split value - BINARY SPLIT.\n",
    "    # \n",
    "    # Split_val should be a numerical value\n",
    "    # For example, your split_val could be the mean of the values of split_attribute\n",
    "    #\n",
    "    # You can perform the partition in the following way\n",
    "    # Numeric Split Attribute:\n",
    "    #   Split the data X into two lists(X_left and X_right) where the first list has all\n",
    "    #   the rows where the split attribute is less than or equal to the split value, and the \n",
    "    #   second list has all the rows where the split attribute is greater than the split \n",
    "    #   value. Also create two lists(y_left and y_right) with the corresponding y labels.\n",
    "\n",
    "    '''\n",
    "    Example:\n",
    "\n",
    "    X = [[3, 10],                 y = [1,\n",
    "         [1, 22],                      1,\n",
    "         [2, 28],                      0,\n",
    "         [5, 32],                      0,\n",
    "         [4, 32]]                      1]\n",
    "\n",
    "    Here, columns 0 and 1 represent numeric attributes.\n",
    "\n",
    "    Consider the case where we call the function with split_attribute = 0 and split_val = 3 (mean of column 0)\n",
    "    Then we divide X into two lists - X_left, where column 0 is <= 3  and X_right, where column 0 is > 3.\n",
    "\n",
    "\n",
    "    X_left = [[3, 10],                 y_left = [1,\n",
    "              [1, 22],                           1,\n",
    "              [2, 28]]                           0]\n",
    "\n",
    "    X_right = [[5, 32],                y_right = [0,\n",
    "               [4, 32]]                           1]\n",
    "\n",
    "    ''' \n",
    "\n",
    "    X_left = []\n",
    "    X_right = []\n",
    "\n",
    "    y_left = []\n",
    "    y_right = []\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    data = np.concatenate((X,y.reshape(-1, 1)), axis=1)\n",
    "    left = data[data[:, split_attribute] <= split_val]\n",
    "    left1 = np.hsplit(left, len(X[0])+1)\n",
    "    right = data[data[:, split_attribute] > split_val]\n",
    "    right1 = np.hsplit(right, len(X[0])+1)\n",
    "\n",
    "    X_left = np.concatenate((left1[0:len(X[0])]), axis=1).tolist()\n",
    "    X_right = np.concatenate((right1[0:len(X[0])]), axis=1).tolist()\n",
    "    y_left = left1[-1].astype(int).tolist()\n",
    "    y_right = right1[-1].astype(int).tolist()\n",
    "\n",
    "    #############################################\n",
    "    return (X_left, X_right, y_left, y_right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(previous_y, current_y):\n",
    "    info_gain = 0\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    entropy_list = []\n",
    "    for i in range(len(current_y)):\n",
    "        current_y[i] = np.array(current_y[i])\n",
    "        (u, c) = np.unique(current_y[i], return_counts=True)\n",
    "        p = len(current_y[i])/len(previous_y)\n",
    "        entropy_list.append(p * entropy(current_y[i]))\n",
    "    entropy_sum = np.sum(entropy_list)\n",
    "    info_gain = entropy(previous_y) - entropy_sum\n",
    "\n",
    "    #############################################\n",
    "    return info_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y):\n",
    "    # Inputs:\n",
    "    #   X       : Data containing all attributes\n",
    "    #   y       : labels\n",
    "    #   TODO    : For each node find the best split criteria and return the split attribute, \n",
    "    #             spliting value along with  X_left, X_right, y_left, y_right (using partition_classes) \n",
    "    #             in the dictionary format {'split_attribute':split_attribute, 'split_val':split_val, \n",
    "    #             'X_left':X_left, 'X_right':X_right, 'y_left':y_left, 'y_right':y_right, 'info_gain':info_gain}\n",
    "\n",
    "    split_attribute = 0\n",
    "    split_val = 0\n",
    "    X_left, X_right, y_left, y_right = [], [], [], []\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    y_array = np.array(y)\n",
    "    X_array = np.hsplit(np.array(X), len(X[0]))\n",
    "\n",
    "    ig_val = 0 \n",
    "    best_val = 0\n",
    "    best_attr = 0\n",
    "    for attr in range(0,len(X[0])):\n",
    "        for val in X_array[attr]:\n",
    "            X_l, X_r, y_l, y_r = partition_classes(X, y, attr, val)\n",
    "            ig = information_gain(y, [y_l, y_r])\n",
    "            if ig > ig_val:\n",
    "                ig_val = ig\n",
    "                best_val = val\n",
    "                best_attr = attr\n",
    "\n",
    "    X_left, X_right, y_left, y_right = partition_classes(X, y, best_attr, best_val)\n",
    "\n",
    "\n",
    "    return {'split_attribute':best_attr, 'split_val':best_val, \\\n",
    "         'X_left':X_left, 'X_right':X_right, 'y_left':y_left, 'y_right':y_right, 'info_gain':ig_val}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {}\n",
    "max_depth = 10\n",
    "\n",
    "def learn(X, y, par_node = {}, depth=0):\n",
    "    # TODO: Train the decision tree (self.tree) using the the sample X and labels y\n",
    "    # You will have to make use of the functions in Utility class to train the tree\n",
    "\n",
    "    # par_node is a parameter that is useful to pass additional information to call \n",
    "    # the learn method recursively. Its not mandatory to use this parameter\n",
    "\n",
    "    # Use the function best_split in Utility class to get the best split and \n",
    "    # data corresponding to left and right child nodes\n",
    "\n",
    "    # One possible way of implementing the tree:\n",
    "    #    Each node in self.tree could be in the form of a dictionary:\n",
    "    #       https://docs.python.org/2/library/stdtypes.html#mapping-types-dict\n",
    "    #    For example, a non-leaf node with two children can have a 'left' key and  a \n",
    "    #    'right' key. You can add more keys which might help in classification\n",
    "    #    (eg. split attribute and split value)\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    max_depth = 10\n",
    "    if len(y) == 1:   # no data in this group\n",
    "        return {\"leaf\": \"yes\", \"label\": y}\n",
    "    elif all(x == y[0] for x in y):   # all y is the same in this group\n",
    "        return {\"leaf\": \"yes\", \"label\": y[0]}\n",
    "    elif depth >= max_depth:   # max depth reached \n",
    "        return None\n",
    "    else:\n",
    "        depth += 1\n",
    "        split_attribute = best_split(X, y)[\"split_attribute\"]\n",
    "        split_val = best_split(X, y)[\"split_val\"]\n",
    "\n",
    "        X_left = best_split(X, y)[\"X_left\"]\n",
    "        X_right = best_split(X, y)[\"X_right\"]\n",
    "        y_left = best_split(X, y)[\"y_left\"]\n",
    "        y_right = best_split(X, y)[\"y_right\"]\n",
    "        \n",
    "        root = \"{} <= {}\".format(split_attribute, split_val)\n",
    "        tree = {root:[]}\n",
    "        left = learn(X_left, y_left, {}, depth)\n",
    "        right = learn(X_right, y_right, {}, depth)\n",
    "        \n",
    "        tree[root].append(left)\n",
    "        tree[root].append(right)\n",
    "        #root[\"left\"] = learn(X_left, y_left, {}, depth)   \n",
    "        #root[\"right\"] = learn(X_right, y_right, {}, depth)\n",
    "        #root[\"attr\"] = split_attribute\n",
    "        #root[\"val\"] = split_val\n",
    "\n",
    "        return tree\n",
    "    #############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, record):\n",
    "    # TODO: classify the record using self.tree and return the predicted label\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    the_tree = tree\n",
    "    root = list(the_tree.keys())[0]\n",
    "    attr, comp, val = root.split()\n",
    "    if record[attr] <= val:\n",
    "        the_tree = the_tree[root][0]\n",
    "    else:\n",
    "        the_tree = the_tree[root][1]\n",
    "    \n",
    "    if not isinstance(the_tree, dict):\n",
    "        return the_tree\n",
    "    else:\n",
    "        return classify(record, the_tree)\n",
    "\n",
    "    #############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    record_array = np.array(record)\n",
    "    labels = []\n",
    "    the_tree = tree\n",
    "    \n",
    "    if type(record[0]) == int or type(record[0]) == float:\n",
    "        while the_tree.get(\"val\"):\n",
    "            if record[the_tree[\"attr\"]] <= the_tree[\"val\"]:\n",
    "                the_tree = the_tree[\"left\"]\n",
    "            else:\n",
    "                the_tree = the_tree[\"right\"]\n",
    "        else:\n",
    "            labels.append(the_tree.get(\"label\"))    \n",
    "        #return labels\n",
    "    else:\n",
    "        for i, c in enumerate(record_array):\n",
    "            while the_tree.get(\"val\"):\n",
    "                if c[the_tree[\"attr\"]] <= the_tree[\"val\"]:\n",
    "                    the_tree = the_tree[\"left\"]\n",
    "                else:\n",
    "                    the_tree = the_tree[\"right\"]\n",
    "            else:\n",
    "                labels.append(the_tree.get(\"label\"))    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class RandomForest(object):\n",
    "num_trees = 10\n",
    "decision_trees = {}\n",
    "\n",
    "# the bootstrapping datasets for trees\n",
    "# bootstraps_datasets is a list of lists, where each list in bootstraps_datasets is a bootstrapped dataset.\n",
    "bootstraps_datasets = []\n",
    "\n",
    "# the true class labels, corresponding to records in the bootstrapping datasets\n",
    "# bootstraps_labels is a list of lists, where the 'i'th list contains the labels corresponding to records in\n",
    "# the 'i'th bootstrapped dataset.\n",
    "bootstraps_labels = []\n",
    "\n",
    "#initiallize\n",
    "#decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bootstrapping(XX, n):\n",
    "    # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n",
    "    #\n",
    "    # TODO: Create a sample dataset of size n by sampling with replacement\n",
    "    #       from the original dataset XX.\n",
    "    # Note that you would also need to record the corresponding class labels\n",
    "    # for the sampled records for training purposes.\n",
    "\n",
    "    sample = [] # sampled dataset\n",
    "    labels = []  # class labels for the sampled records\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    XX = np.asarray(XX)\n",
    "    xx_sample = np.stack(random.choices(XX, k=n))\n",
    "    xx_sample1 = np.hsplit(xx_sample, len(xx_sample[0]))\n",
    "    sample = np.concatenate((xx_sample1[0:-1]), axis=1)\n",
    "    labels = xx_sample1[-1]\n",
    "\n",
    "    #############################################\n",
    "    return (sample, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(XX):\n",
    "    # Initializing the bootstrap datasets for each tree\n",
    "    for i in range(num_trees):\n",
    "        data_sample, data_label = _bootstrapping(XX, len(XX))\n",
    "        bootstraps_datasets.append(data_sample)\n",
    "        bootstraps_labels.append(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting():\n",
    "    # TODO: Train `num_trees` decision trees using the bootstraps datasets\n",
    "    # and labels by calling the learn function from your DecisionTree class.\n",
    "    ### Implement your code here\n",
    "    #############################################\n",
    "    for i in range(len(bootstraps_datasets)):\n",
    "        decision_trees[i]=learn(bootstraps_datasets[i], bootstraps_labels[i], {}, 0)\n",
    "    #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(X):\n",
    "    y = []\n",
    "\n",
    "    for record in X:\n",
    "        # Following steps have been performed here:\n",
    "        #   1. Find the set of trees that consider the record as an out-of-bag sample.\n",
    "        #   2. Predict the label using each of the above found trees.\n",
    "        #   3. Use majority vote to find the final label for this recod.\n",
    "        votes = []\n",
    "\n",
    "        for i in range(len(bootstraps_datasets)):\n",
    "            dataset = bootstraps_datasets[i]\n",
    "\n",
    "            if record not in dataset:\n",
    "                #OOB_tree = decision_trees[i]\n",
    "                effective_vote = classify(decision_trees[i],record)\n",
    "                votes.append(effective_vote)\n",
    "        v = np.array([item for sublist in votes for item in sublist]).astype(int).tolist()\n",
    "        counts = np.bincount([item for sublist in v for item in sublist])\n",
    "\n",
    "        if len(counts) == 0:\n",
    "            # TODO: Special case\n",
    "            #  Handle the case where the record is not an out-of-bag sample\n",
    "            #  for any of the trees.\n",
    "            # NOTE - you can add few lines of codes above (but inside voting) to make this work\n",
    "            ### Implement your code here\n",
    "            #############################################\n",
    "            #d = DecisionTree(max_depth=10)\n",
    "            vote = classify(tree=decision_trees[1], record=record)\n",
    "            y = np.append(y, vote)\n",
    "            #############################################\n",
    "        else:\n",
    "            y = np.append(y, np.argmax(counts))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapping(XX=XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-15229831e44e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfitting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-ed206f5ecc1e>\u001b[0m in \u001b[0;36mfitting\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstraps_datasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mdecision_trees\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstraps_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstraps_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m#############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-353d995cecc1>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(X, y, par_node, depth)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{} <= {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_attribute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-353d995cecc1>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(X, y, par_node, depth)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mX_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X_left\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mX_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"X_right\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0my_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_left\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0my_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_right\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6362d5a7b31f>\u001b[0m in \u001b[0;36mbest_split\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mX_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minformation_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_r\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mig\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mig_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0b33edcda521>\u001b[0m in \u001b[0;36mpartition_classes\u001b[1;34m(X, y, split_attribute, split_val)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_attribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0msplit_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mleft1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_attribute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0msplit_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting(X=X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
